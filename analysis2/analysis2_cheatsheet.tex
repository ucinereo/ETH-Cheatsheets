% Configuration
\documentclass[a4paper, 10pt]{article}

% Formatting
\usepackage[landscape, left=0.75cm, top=1.0cm, right=0.75cm, bottom=1.5cm, footskip=15pt]{geometry}
\setlength{\columnsep}{0.5cm}
\usepackage{flowfram}
\ffvadjustfalse
\Ncolumn{3}
\usepackage[compact]{titlesec}

% ------------------------
% Imports and commands
% ------------------------

% Language stuff
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

% Math stuff
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bm}

\newtheorem*{corollary}{Cor}
\newtheorem*{lemma}{Lemma}
\newtheorem*{proposition}{Prop}

\theoremstyle{definition}
\newtheorem*{theorem}{Thm}
\newtheorem*{definition}{Def}

\newtheoremstyle{colored}{}{}{}{}{\bf}{}{.5em}{{\thmnote{(#3) }}}
\theoremstyle{colored}
\newtheorem*{note_wrapper}{}

\newtheoremstyle{ex}{2pt}{5pt}{}{}{\bf}{}{0pt}{{\thmnote{(#3) }}}
\theoremstyle{ex}
\newtheorem*{exercise}{}

\newtheoremstyle{named}{}{}{}{}{\bfseries}{.}{.5em}{\thmnote{#3}}
\theoremstyle{named} 
\newtheorem*{ntheorem_wrapper}{Theorem}

% Colored boxes
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage{framed}
\mdfsetup{skipabove=-2pt,skipbelow=-2pt}

\definecolor{cwhite}{HTML}{d7dbd7}
\mdfdefinestyle{important}{
    linecolor=yellow,
    linewidth=0pt,
    innertopmargin=-6pt,
    innerbottommargin=2pt,
    innerrightmargin=2pt,
    innerleftmargin=2pt,
    leftmargin=0pt,
    rightmargin=0pt,
    outerlinewidth=0pt,
    backgroundcolor=cwhite,
}

\newenvironment{ntheorem}%
    {\begin{mdframed}[style=important]\begin{ntheorem_wrapper}}%
    {\end{ntheorem_wrapper}\end{mdframed}}

\definecolor{cgreen}{HTML}{2ecc71} 
\definecolor{bgreen}{HTML}{FFED8A}
\mdfdefinestyle{trick}{
    linecolor=yellow,
    linewidth=0pt,
    innertopmargin=-6pt,
    innerbottommargin=2pt,
    innerrightmargin=2pt,
    innerleftmargin=2pt,
    leftmargin=0pt,
    rightmargin=0pt,
    outerlinewidth=0pt,
    backgroundcolor=bgreen,
}

\newenvironment{note}%
    {\begin{mdframed}[style=trick]\begin{note_wrapper}}%
    {\end{note_wrapper}\end{mdframed}}

% Table stuff
\usepackage{tabularx} % tabularx since the width should be handled automatically
\usepackage{booktabs}
\usepackage{makecell}

% Graph stuff
\usepackage{pgfplots}

% Miscellaneous
\usepackage{hyperref}
\hypersetup{colorlinks=true, urlcolor=blue, linkcolor=blue, citecolor=blue}

\usepackage{enumitem}
\setitemize{itemsep=0.5pt, topsep=0pt}
\setenumerate{itemsep=0.75pt, topsep=0pt}

\usepackage{graphics}

\newlist{exanswers}{itemize}{2}
\setlist[exanswers]{itemsep=2pt, topsep=2pt}
\setlist[exanswers,1]{label=$\diamond$,leftmargin=5mm}
\setlist[exanswers,2]{label=\textbullet,leftmargin=1mm}

% Custom commands
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\BO}{\mathcal{O}}
\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}}

% Metadata
\title{Analysis II Summary}
\author{Nicola Studer \\ \href{mailto:nicstuder@student.ethz.ch}{nicstuder@student.ethz.ch}}
\date{\vspace{-5ex}}


% ------------------------
% Document
% ------------------------

\begin{document}
\maketitle

\section{Ordinary differential equations}
\[F(x, y(x), y'(x), \ldots, y^{(n)}) = 0\]
Given a function \(F\) of \(x, y\), where \(x\) and \(y\) are functions themselves. \(F\) is an implicit ODE of \textbf{order} \(n\).

\begin{note}[Linear ODE's]
    Linear ODE with \(a_{k-1}, \ldots, a_0, b\) as cont. functions of \(x\) in \(I \subset \R\):
    \[y^{(k)} + a_{k-1}(x)y^{(k-1)} + \ldots + a_1(x)y' + a_0(x)y = b(x)\]
    If \(\bm{b = 0}\) then the ODE is called \textbf{homogeneous}.
\end{note}

\begin{ntheorem}[Properties of linear ODEs]
    \(\;\)
    \begin{enumerate}
        \item all coefficients are continuous functions
        \item no products of \(y\) and its derivatives
        \item no powers of \(y\) and its derivatives
        \item no functions which depend on \(y\) or its derivatives
        \item no leading coefficient in front of the highest derivative
    \end{enumerate}
\end{ntheorem}

\begin{theorem}[Main result about linear ODEs]
    \(\;\)
    \begin{enumerate}
        \item Let \(\mathcal{S}_0\) be the set of solutions when \(b = 0\). Then \(\mathcal{S}_0\) is a vector space of dimension \(k\). If \(f_1, \ldots, f_k\) are the solutions, then so is \(a_1f_1+ \ldots a_kf_k\).
        \item For any \textbf{initial condition} (i.e. for any choice of \(x_0 \in I\)) there is a unique solution \(f \in \mathcal{S}_0\) such that: \\
        \(f(x_0) = y_0, f'(x_0) = y_1, \ldots, f^{(k-1)}(x_0) = y_{k-1}\)
        \item For any arbitrary \(b(x)\), the set of solutions of the ODE is \(\mathcal{S}_b = \{f + f_p \ | \ f \in \mathcal{S}_0\}\) where \(f_p\) is a particular solution of the ODE.
        \item For any initial condition there is a unique solution \(f \in \mathcal{S}_b\).
    \end{enumerate}
\end{theorem}

\subsection{Linear ODE of order 1}
\(y' + a(x)y = b(x)\) 

\begin{note}[How to solve]
        \(1.\) Solve the homogeneous ODE:
        \begin{align*}
            && y' + ay &= 0 & \\
            &\implies & y' &= - ay & \\
            &\implies & \tfrac{y'}{y} &= -a & (\text{assume \(y \neq 0\) no \(I\)}) \\
            &\implies & \ln(|y|) &= -A + C & (A(x) = \smallint a(x) \,dx) \\
            &\implies & y &= e^{-A + C} = z\cdot e^-A & (\text{simplify})
        \end{align*}
        \(2.\) Find a particular solution \(f_p: I \to \C\) with either an educated guess, variation of parameters or integration factor such that \(f'_p + a(x)f_p = b(x)\).
\end{note}

\subsubsection*{Method of undetermined coefficients}
\begin{tabular}{c|c}
    \(\bm{b(x)}\) & \textbf{Guess} \\
    \hline
    \(a e^{\alpha x}\) & \(c e^{\alpha x}\) \\
    \hline
    \makecell{\(a \sin(\beta x)\) \\ \(a \cos(\beta x)\)} & \(D \sin(\beta x) + E \cos(\beta x)\) \\
    \hline
    \makecell{\(a e^{\alpha x} \sin(\beta x)\) \\ \(a e^{\alpha x} \cos(\beta x)\)} & \(D e^{\alpha x} \sin(\beta x) + E e^{\alpha x} \cos(\beta x)\) \\
    \hline
    \(P_n(x) e^{\alpha x}\) & \(Q_n(x) e^{\alpha x}\) \\
    \hline
    \makecell{\(P_n(x) e^{\alpha x} \sin(\beta x)\) \\ \(P_n(x) e^{\alpha x} \cos(\beta x)\)} & \(e^{\alpha x} (Q_n(x) \sin(\beta x) + R_n(x) \cos(\beta x))\) \\
\end{tabular}

\begin{enumerate}
    \item If \(b(x)\) is a linear combination of the basis functions, try a linear combination.
    \item If \(f_p = f_0\), try to multiply it with \(x^m\) where \(m\) denotes the multiplicity of the root.
\end{enumerate}

\subsubsection*{Variation of parameters}
\begin{enumerate}
    \item Assume \(f_p = z(x) \cdot e^{-A(x)}\) for a function \(z: I \to \C\)
    \item Insert the equation and construct \(z\):
    \begin{align*}
        &&y' + ay &= b \\
        &\implies& z'e^{-A} &= b \\
        &\implies& z' &= be^{A} \\
        &\implies& z &= \smallint_{x_0}^x b(t)e^{A(t)}\,dt \\
        &\implies& f_p &= \smallint_{x_0}^x b(t) e^{A(t)}\,dt \cdot e^{-A(x)}
    \end{align*}
\end{enumerate}

\subsubsection*{Integration Factor}
\begin{align}
    \tag{\(\dagger\)} \frac{dy}{dx} + a(x) y = b(x)
\end{align}
\begin{enumerate}
    \item Multiply both sides of (\(\dagger\)) with \(e^{A(x)} = e^{\smallint a(x)\,dx}\) \par
    \centering
    \(\frac{dy}{dx} e^{\smallint a(x)\,dx} + ya(x)e^{\smallint a(x)\,dx} = b(x)e^{\smallint a(x)\,dx}\)
    \item \raggedright Observe the product rule on the left hand side: \par
    \centering
    \(\frac{d}{dx}ye^{\smallint a(x)\,dx} = b(x)e^{\smallint a(x)\,dx}\)
    \item \raggedright Call \(y e^{\smallint a(x)\,dx}:=z(x) \implies y = z(x)e^{-A(x)}\) (\(\ddagger\)) \par
    \centering
    \(\frac{d}{dx}z(x) = b(x)e^{\smallint a(x)\,dx}\)
    \item \raggedright Solve for \(z(x)\) \par
    \centering
    \(z(x) = \int b(x) e^{A(x)}\,dx\)
    \item \raggedright Insert (\(\ddagger\)):
    \(y = \left(\int b(x)e^{A(x)} \,dx\right) e^{-A(x)}\)
\end{enumerate}

\subsection{Linear ODE with constant coefficients}
\[Dy = b(x) \quad D = \frac{d^k}{dx^k} + a_{k - 1} \frac{d^{k-1}}{dx^{k-1}} + \ldots + a_0\]

\subsubsection*{1. Solve homogeneous equation}
Assume \(y = e^{\lambda x}\) for some \(\lambda \in \C\). We put that guess in the initial formula and get the following (simplified) form:
\[e^{\lambda x}(\lambda^k + a_{k-1}\lambda^{k-1} + a_{k-2}\lambda^{k-2} + \ldots + a_0) = e^{\lambda x} \cdot P(\lambda) = 0\]
Since \(e^{\lambda x}\) can never be \(0\) it follows that \(P(\lambda)\) must be \(0\). \(P(\lambda)\) is called the \textbf{characteristic polynomial} with its roots called \textbf{eigenvalues}.

\begin{theorem}
    \(D e^{\lambda x} = 0 \iff \lambda\) is a root of \(P_D(\lambda)\)
\end{theorem}

\begin{note}[Solutions]
    The functions \(f_{i, m}: x \mapsto x^m e^{\lambda_i x}\) span the solution space \(S_0\) with \(m\) as the multiplicity of \(\lambda_i\).

    \begin{itemize}
        \item If \(\lambda = a + ib\) is root \(P(\lambda)\), then \(P(\overline{\lambda})\) is a root as well.
        \item Root complex: \(e^{(a + bi) \cdot x} = e^{ax}[\cos(bx) + i \sin(bx)]\)
        \item The particular solution can be guessed
        \item If in the "undetermined coefficients" method \(b = e^{\alpha x}\), but \(\alpha\) is a root of \(P(\lambda)\) with \(m = k\), then we try \(zx^k \cdot e^{\alpha x}\)
    \end{itemize}
\end{note}

\begin{theorem}
    \(D(y_1 + y_2) = D(y_1) + D(y_2) = b_1 + b_2\)
\end{theorem}

\section{Differential calculus in \(\R^n\)}
\begin{definition}[Vector Field]
    \(f: \R^n \to \R^m \quad (m > 1)\)
\end{definition}

\begin{definition}[Scalar Field]
    \(f: \R^n \to \R\)
\end{definition}

\begin{definition}[Monomial]
    \[f :\begin{cases}
        \R^n \to \R \\
        (x_1, x_2, \ldots, x_n) \mapsto \alpha x_1^{d_1} x_2^{d_2} \ldots x_n^{d_n}
    \end{cases}\]
\end{definition}

\begin{definition}[Converges of sequences]
    Let \((x_k)_k \subset \R^n\) be a sequence.
     and \(y \in \R^n\). \(\lim\limits_{k \to \infty}x_k = y \iff\)
    \begin{enumerate}
        \item \(\forall \epsilon > 0 \, \exists N \geq 1 \, \forall k \geq N: ||x_k - y|| < \epsilon\)
        \item For each \(i\), \(1 \leq i \leq n\) the sequence \((x_{k, i}) \subset \R\) fo real numbers converges to \(y_i \in \R\)
        \item The sequence of real numbers \(||x_k - y|| \to 0\)
    \end{enumerate}
        
\end{definition}

\begin{definition}
    \(f: X \subset \R^n \to \R^m\), \(x_0 \in X\).
    \(f\) has a limit \(y \in \R^m\) as \(x \to x_0\) (with \(x \neq x_0\)) if
    \begin{enumerate}
        \item \(\forall \epsilon > 0 \, \exists \delta > 0 \, \forall x \in X, x \neq x_0: ||f(x) - y|| < \epsilon\)
        \item \(\forall\) sequences \((x_k)\) in \(X\) with \(\lim x_k = x_0\) and \(x_k \neq x_0\) converges the sequence \(f(x_k)\) to \(y\).
    \end{enumerate}
\end{definition}

\begin{definition}[Continuitity]
    \(f: X \to \R^m\) cont. at \(x_0\) if
    \begin{enumerate}
        \item \(\forall \epsilon > 0 \, \exists \delta > 0 \, \forall x \in X : \)
        \[||x-x_0|| < \delta \implies ||f(x) - f(x_0)|| < \epsilon\]
        \item \(\forall\)seq. \((x_k)\) with \(\lim x_k = x_0: \lim f(x_k) = f(x_0)\)
    \end{enumerate}
    \(f\) cont. on \(X\)if it is cont. \(\forall x_0 \in X\).
\end{definition}

\begin{corollary}
    \begin{enumerate}
        \item \(f_1: \R^n \to \R^m, f_2: \R^n \to \R^s\) cont., then \(f: (f_1, f_2): \R^n \to \R^{m + s}, x \mapsto (f_1(x), f_2(x))\) is cont.
        \item \(f: \R^n \to \R^m, x \mapsto (f_1(x), f_2(x), \ldots)\) cont.\\  \(\iff  \forall 1 \leq i \leq m f_i: \R^n \to \R\) are cont.
        \item \(f: \R^n \to \R^m, x \mapsto Ax\) and polynomials are cont.
        \item Sums/products of cont. functions are cont.
        \item Functions with separated variables are cont. if each variable is cont.
        \item Composition of cont. functions are cont.
        \item If \(f: \R^2 \to \R\) is cont. Fix \(y_0 \in \R\). \\ Define \(g_{y_0}(x) := f(x, y_0)\). Then \(g_{y_0}: \R \to \R\) is cont.
        \[\not\Rightarrow f: \R^2 \to \R \ \text{is cont.}\]
    \end{enumerate}
\end{corollary}

\begin{ntheorem}[Squeeze]
    \(f, g, h : \R^n \to \R\), \(\forall x \in \R^n: f(x) < g(x) < h(x)\)
    \[\lim_{x \to a} f(x) = L = \lim_{x \to a} h(x) \implies \lim_{x \to a}g(x) = L\]
\end{ntheorem}

\begin{note}[Polar Coordinates]
    For \(f: \R^2 \to \R\) polar coordinates are sometimes helpful.
    \(x = r \cos \theta \quad y = r \sin \theta\)
    \[\lim_{(x, y) \to (0, 0)}f(x, y) = \lim_{(r\cos\theta, r\sin\theta)  \to (0,0)}f(x, y) = \ldots = \lim_{r \to 0} \zeta\]
\end{note}

\begin{definition}[Bounded]
    \begin{enumerate}
        \item \(X \subseteq \R^n\) is bounded if \(\{||x|| \ | \ x \in X\}\) is bounded in \(\R\).
        \item \(X \subseteq \R^n\) is closed if \(\forall (x_k) \subset X\) that converges in \(\R^n\) to some vector \(y \in \R^n\), we have that \(y \in X\).
        \item \(X \subseteq \R^n\) is compact if it is closed and bounded.
    \end{enumerate}
\end{definition}

\begin{theorem}
    \(f: \R^n \to \R^m\) cont. \(\forall Y \subseteq \R^m\) closed, the set \(f^{-1}(Y)\) is closed.
\end{theorem}

\begin{theorem}[Min-Max]
    \(X \subseteq \R^n\) compact. \(f: X \to \R\) cont. \(\implies \exists x_+, x_- \in X: f(x_+) = \sup_{x \in X}(f(x)) \quad f(x_-) - \inf_{x \in X} f(x)\)
\end{theorem}

\begin{definition}
    open interval... todo
\end{definition}

\subsection{Partial derivatives}
\ldots

\begin{definition}
    \(f: \R^n \to \R^m\) is diff. at \(x_0\), with differential \(u\), if there exists a linear map \(u: \R^n \to \R^m\) such that
    \[\lim_{\substack{x \to x_0 \\ x \neq x_0}} \frac{f(x) - (f(x_0) + u(x - x_0))}{||x-x_0||} = 0\]

    The linear map \(u: \R^n \to \R^m\) is called (total) \textbf{differential} of \(f\) at \(x_0\), denoted by \(df(x_0), d_xf\)
\end{definition}

\begin{note}[Warning]
    For \(f: \R^n \to \R^m\) the differential \(df(x_0)\) is not a number but is a linear map. 
\end{note}

\begin{theorem}
    \(f: \R^n \to \R^m\) diff. at \(x_0\)
    \begin{enumerate}
        \item \(f\) is cont. at \(x_0\)
        \item \(f\) has all partial derivatives at \(x_0\)
        \item The matrix that represents the differential in the standard basis is \(J_f(x_0) = \left(\frac{\partial f_i}{\partial x_j} (x_0)\right)\)
    \end{enumerate}
\end{theorem}

\begin{definition}
    \(f: \R^n \to \R^m\) diff. at \(x_0\) with differential \(d_{x_0}f = U: \R^n \to \R^m\). The graph of the affine linear map \(g(x) = f(x_0) + u(x - x_0)\) is called ht etangend space at \(x_0\) to the graph of \(f\).
\end{definition}

\begin{note}[Properties of the differential]
    \begin{enumerate}
        \item if \(f, g: X \subset \R^n \to \R^m\) diff. in \(x_0\), then so is \(f + g\) and \(d_{x_0}(f + g) = d_{x_0}f + d_{x_0}g\)
        \item If \(f, g: \R^n \to \R\) diff. at \(x_0\) then so is \(fg\). If \(g\) is non-zero, then also \(\frac{f}{g}\). \(d_{x_0}(fg) = (d_{x_0}f)g(x_0) + f(x_0)(d_{x_0}g)\)
        \item 
    \end{enumerate}
\end{note}

\begin{ntheorem}[Partial Convergence]
    if \(f : X \to \R^m\) has all partial derivatives \(\frac{\partial f_i}{\partial x_j}: X \to \R^m\) and if these functions are cont. in \(X\) then \(f\) is differentiable on \(X\).
\end{ntheorem}

\ldots add the stuff from the last lectures

\begin{note}[Parameterized curve]
    \(\gamma: [a, b] \to \R^n\), cont. and piecewise \(C^1\). \(\gamma\) is a parameterized curve, \(\gamma(t)\) is a parameterization of the curve \(\Im \gamma = \gamma([a, b])\).
\end{note}

\subsection*{Higher order partial derivatives}
\begin{definition}[Change of variables]
    \(X \subset \R^n\) open, \(f: X \to \R^n\) diff. \(f\) is a change of variables around \(x_0\) if there is a radius \(r > 0\), such that the restriction of \(f\) to Ball \(B_r(x_0) := \{x \in \R^n \ | \ ||x - x_0|| < r\}\) has the property that the image \(Y = f(B_r(x_0))\) is open in \(\R^n\) and \(\exists\) diff. map \(g: Y \to B\) s.t. \(f \circ g = id = g \circ f\).
\end{definition}

\begin{ntheorem}[Inveres function theorem]
    \(X \subseteq \R^n\) open, \(f: X \to \R^n\) diff. If \(x_0 \in X\) is such that \(\det(J_f(x_0)) \neq 0\), then \(f\) is a change of variables around \(x_0\). Moreover the Jacobian of \(g\) is determined by \(J_g(f(x_0)) = J_f(x_0)^{-1}\).
\end{ntheorem}

\begin{note}
    This is the analog of the fact that in \(n = 1\) for a function \(f : I \to \R\) \(f\) is bijective from \(I\) to its image if \(f' > 0\) (or \(f' < 0\))
\end{note}

\begin{definition}
    \(X \subset \R^n\) open, \(f: X \to \R^m\). We say \(f\) is diff. of class \(C^1\) if \(f\) is diff. on \(X\) and all its partial derivatives are continuous.

    The set of all \(C^1\) functions are denoted by \(C^1(X ; \R^m)\).

    Let \(k \geq 2\), \(f \in C^k(X; R^m)\) if its diff. and each \(\partial_{x_i}f: X \to \R^m\) with \(1 \leq i \leq n\) is of class \(C^{k - 1}\).

    \(f\) is smooth or \(C^\infty\) if \(f \in C^k \forall k\).
\end{definition}

\begin{note}
    All polynomials, trig. functions, exponential functions are of class \(C^\infty\)
\end{note}

\begin{ntheorem}[Mixed derivatives commute]
    If \(f \in C^k\), \(k \geq 2\) then the partial derivatives of oder \(\leq k\) are independent of the order of differentiation.
    \[\frac{\partial}{\partial x_{i_k}} \dots (\frac{\partial}{\partial x_{i_2}}(\frac{\partial f}{\partial x_{i_1}})) = \frac{\partial^k}{\partial x_{i_k} \cdot \ldots \cdot \partial x_{i_2} \cdot \partial x_{x_{i_1}}}\]
\end{ntheorem}

\begin{definition}[Hessian]
    \(f: X \to \R, X \subset \R^n\). If \(f \in C^2(X;\R)\), \(x_0 \in X\).
    \[\text{Hess}_f(x_0) = \nabla^2 f(x_0) = \left(\frac{\partial^2 f(x_0)}{\partial x_i \partial x_j}\right)_{1 \leq i,j \leq n}\]
\end{definition}

\begin{definition}[Taylor polynomial of order 1]
    For \(f: \R^n \to \R\) an approximation to \(f(y)\) for \(y\) close to \(x_0\):
    \begin{align*}
        T_1 f(x_0; y) &= f(x_0) + \nabla f(x_0) \cdot y \\
        &= f(x_0) + \frac{\partial f}{\partial x_1} (x_0) y_1 + \ldots \frac{\partial f}{\partial x_n} (x_0) y_n
    \end{align*}
\end{definition}

\begin{note}
    Add the taylor polynomial for order 2 expliciiiit
\end{note}

\begin{definition}[\(k\)-th order Taylor polynomials]
    \begin{multline*}
        T_kf(x_0;y) = f(x_0) + \sum_{i = 1}^n \frac{\partial f}{\partial x_i} (x_0) y_i + \ldots + \\ \sum_{m_1 + \ldots m_n = k} \frac{1}{m_1! \cdot m_2! \cdot m_n!} \frac{\partial^k f}{\partial x_1^{m_1} \ldots \partial x_n^{m_n}}(x_0) \cdot y_1^{m_1 \ldots y_n^{m_n}}
    \end{multline*}
\end{definition}

\begin{ntheorem}[Taylor Approximation]
    Let \(f \in C^k(X; \R), x_0 \in X\)
    \[f(x) = T_k f(x_0, x - x_0) + E_k(f, x, x_0)\]
    which implies
    \[\lim_{x \to x_0} \frac{E_k(f, x, x_0)}{||x - x_0||^2} = 0\]
\end{ntheorem}

\begin{definition}
    Add the stuff for minima and maxima
\end{definition}

\begin{theorem}
    \(f: X \subset R^n \to \R\) diff. If \(X\) closed and bounded, then every global extrema of \(f\) exists and is either at a point \(x_0 \in\) interior of \(x\) for which \(\nabla f(x_0) = 0\) or \(x_0 \in\) boundary of \(x\).
\end{theorem}

\begin{definition}[Non-degenerate critical point of \(f \in C^2(X, \R)\)]
    \[\det(\text{Hess}_f(x_0)) \neq 0\]
\end{definition}

\begin{theorem}
    \(f: X \subset \R^n \to \R\), \(f \in C^2(X, \R)\). Let \(x_0 \in X\) be a critical point of \(f, \nabla f(x_0) = 0\). Then
    \begin{enumerate}
        \item \(\text{Hess}_f(x_0) > 0 (\text{pos. def.}) \implies\) loc. min.
        \item \(\text{Hess}_f(x_0) < 0 (\text{neg. def.}) \implies\) loc. max.
        \item \(\text{Hess}_f(x_0)\) indefinite \(\implies\) saddle point.
    \end{enumerate}
\end{theorem}

\begin{note}
    If \(\nabla f(x_0) = 0\), but also \(\det \text{Hess}_f(x_0) = 0\), the we have to calculate each case individually.
\end{note}

\begin{note}[General recipe for finding \textbf{global} extrema:]
    Let \(f: X \subseteq \R^n \to \R\), compact and \(f \in C^2(X)\).
    \begin{enumerate}
        \item Calculate \(\nabla f(x)\) and \(\text{Hess}_f(x)\)
        \item Find all solutions of \(\nabla_f(x) = 0\), \(S := \{\)
    \end{enumerate}
\end{note}

\section*{Integration in \(\R^n\)}
\subsection*{Line Integrals}

\begin{definition}
    Let \(\gamma: [a, b] \to \R^n\) be a curve in \(\R^n\). \(X \subset \R^n\) a subset of \(\R^n\) which contains the image of \(\gamma\). \(v: X \to \R^n\) a continuous function. The integral
    \[\int_a^b (v(\gamma(t)) \cdot \gamma'(t)) \, dt\]
    is called the line or path integral of \(v\) along \(\gamma\)
\end{definition}

\begin{note}[Other notations] \ \\
    \begin{itemize}
        \item \(\int\limits_\gamma v \,ds\) if \(v = (v_1(x), v_2(x), \ldots, v_n(x))\) and \(\gamma(t) = (\gamma_1(t), \gamma_2(t), \ldots \gamma_n(t))\) then \(ds\) represents \(\gamma'(t) \,dt\), multiplied by scalar product.
    \end{itemize}
\end{note}

\begin{ntheorem}[Properties of the line intergral] \ \\
    \begin{itemize}
        \item It is independent of orientation preserving reparametrization of the curve.
        
        Reparametrization: if \(\gamma: [a, b] \to \R^n\), \(\sigma: [c, d] \to [a, b]\) which is \(C^1\) s.t. \(\sigma(c) = a\) and \(\sigma(d) = b\) and \(\sigma'(t) > 0\) then \(\tilde{\gamma} = \gamma \circ \sigma: [c, d] \to \R^n\)
    \end{itemize}
\end{ntheorem}

Suppose \(f: X \to \R^n\), a vector field such that \(\exists g: X \to \R^n\), \(g \in C^1\), ...

\begin{definition}
    A diff. function \(g: X \subset \R^n \to \R\), such that \(\nabla g = f\) is called a potential for \(f\).
\end{definition}

\begin{theorem}
    \(f: X \subseteq \R^n \to \R^n, C^1\) vector field. If \(f\) conservative then \(\frac{\partial f_j}{\partial x_i} = \frac{\partial f_i}{\partial x_j}\) for \(1 \leq i, j \leq n\)
\end{theorem}

\begin{definition}
    \(f: X \subseteq \R^3 \to \R^3, C^1\), then the curl of \(f\) is defined as
    \[\text{curl}(f) := \begin{pmatrix}
        \partial_y f_4 - \partial_z f_2 \\
        \partial_z f_1 - \partial_x f_3 \\
        \partial_x f_2 - \partial_y f_1
    \end{pmatrix}\]
\end{definition}

\begin{theorem}
    \(f: \R^3 \to \R^3\) \(f\) cons. \(\implies \text{curl}(f) = 0\)
\end{theorem}

\begin{note}
    If \(f\) cons. \(\implies\) sym. of partials. But \(\not\Leftarrow\) whether the symmetry implies conservative or not depends on where \(f\) is defined.
\end{note}

\begin{definition}
    A subset \(X \subseteq \R^n\) is start shaped if \(\exists x_0 \in X\) such that \(\forall x \in X\) the line segment joining the \(x\) to \(x_0\) is contained in \(X\).
\end{definition}

\begin{definition}
    A subset \(X \subseteq \R^n\) is convex, when for any \(x, y \in X\) the line segment from \(x\) to \(y\) is contained in \(X\). convex \(\implies\) star-shaped
\end{definition}

\begin{theorem}
    If \(X\) start-shaped open and \(f \in C^1\) vector field. Then \(\frac{\partial f_i}{\partial x_j} = \frac{\partial f_j}{\partial x_i}\) for \(\forall 1 \leq i, j \leq n\). Implies that \(f\) is conservative.
\end{theorem}

t.b.d. riemann inteagral defintions

\begin{theorem}
    \(f\) is cont. and bounded on \(Q\), then \(f\) is integrable.
\end{theorem}

\begin{definition}
    For \(1 \leq m \leq n\) a \(m\)-parameterized set or parameterized \(m\)-set is a continuous function \(\phi: [a_1, b_1] \times \ldots \times [a_m, b_m] \to \R^n\) which is \(C^1\) on \((a_1, b_1) \times \ldots \times (a_m, b_m)\)
\end{definition}

\begin{definition}
    A set \(Y \subseteq \R^n\) is called negligible if \(\exists\)finitely mani \(\phi_i\), parameterized \(m_i\)-sets with \(m_i \leq n\) such that \(1 \leq i \leq k\)
    \[Y \subseteq \bigcup_{i = 1}^k \phi_i(x_i)\]
    where \(\phi_i: x_i \to \R^n\)
\end{definition}

\end{document}
