\section{Random variables}

Let \((\O, \F, \P)\) be a probability space. A random variable is \textbf{measurable} map \(X: \Omega \to \R\)  such that for all \(a \in \R\):
\[\{\omega \in \O \mid X(\omega) \leq a\} \in \F\]

Furthermore we can define \textbf{events} in terms of a \textbf{random variable} where we use an abuse of notation:
\[\{X \leq a\} = \{\omega \in \O \mid X(\omega) \leq a\}\]
Which has a probability of \(\P(X \leq a) = \P(\{X \leq a\})\).

\begin{definition*}[Preimage of a random variable \(X\)]
  \[X^{-1}(A) = \{\omega \in \O \mid X(\omega) \in A\} = \bm{"X \in A"} \quad A \subset \R\]
  \(X\) is \textbf{\(\bm{\F}\)-measurable} if \(\forall B \subsetneq \R\), \(B\) closed: \(X^{-1}(B) \in \F\).
\end{definition*}

\begin{definition*}[Distribution of a Random Variable]
  For \(A \in \B(\R)\), we define the distribution (\textbf{law}) of \(X\) as
  \[\mu(A) = \P_X(A) := \P(X^{-1}(A)) = \P(\{\omega \in \O \mid X(\omega) \in A\})\]
\end{definition*}

\begin{definition*}[Cumulative Distribution Function (CDF)]
  Let \(X\) be a random variable on the probability space \((\O, \F, \P)\), the CDF \(F_X: \R \to [0, 1]\) is defined by
  \[\forall x \in \R \quad F_X(x) = \P(X^{-1}((-\infty, x))) =:\P(X \leq x) \]
\end{definition*}
Properties of the CDF (characterized by RCLL, Càdlàg):
\begin{itemize}
  \item \(a < b \implies \P(a < X \leq b) = F_X(b) - F_x(a)\)
  \item \(F_X\) is monotonically increasing
  \item \(F_X\) is right-continuous, i.e. \(\lim_{y \to x^+} F_X(y) = F_X(x)\)
  \item \(\lim_{x \to -\infty} F_X (x) = 0\) and \(\lim_{x \to \infty} F_X(x) = 1\)
\end{itemize}

\begin{definition*}[Independence of random variables]
  The RVs \(X_1, \ldots, X_n\) are called independent, if
  \begin{align*}
    \forall x_1, \ldots, x_n \in \R: \quad & \P(X_1 \leq x_1, \ldots, X_n \leq x_n) = \\
    & \P(X_1 \leq x_1) \cdot \ldots \cdot \P(X_n \leq x_n)
  \end{align*}
\end{definition*}

\subsection{Discrete random variables}
A random variable \(X\) is called \textbf{discrete} if the set of values it can output \(\DX\), is a discrete (a finite or countable set).

\begin{ddefinition*}[Probability Mass Function (PMF)]
  Let \(X\) be a discrete random variable and \(\DX\) be the set of all its values. The probability mass function \(p_x(x)\) for each \(x \in \DX\) is defined by:
  \[p_X(x) = \P(X = x) = \P_X(\{x\}) = \P(X^{-1}(\{x\}))\]
\end{ddefinition*}

\begin{ddefinition*}[CDF of a discrete random variable] \vspace{-5pt}
  \[F_X(x) = \P(X \leq x) = \sum_{x \in \DX} p_X(x)\]
\end{ddefinition*}

\subsection{Continuous Random Variable}
A random variable \(X\) is called \textbf{continuous} if the set of values it can produce is uncountably infinite and the probability of attaining a single value is zero.

\begin{cdefinition*}[Probability Density Function (PDF)]
  Let \(X\) be a continuous random variable. If there exists a (measureable) function \(f_x: \R \to [0, \infty)\), such that
  \[\P_X(I) = \P(X \in I) = \int_I f_x(x) \,dx\]
  for all intervals \(I\) in \(\R\), we call it the \textbf{PDF}.
\end{cdefinition*}

Notice that \(\int_\R f_x(x) \, dx = 1\) since \(\P_X(\R) = 1\).

\begin{cdefinition*}[CDF of a continuous random variable] \vspace{-5pt}
  \[F_x(x) = \P(X \leq x) = \int_{-\infty}^x f_x(t) \,dt = \P_X((-\infty, x])\]
\end{cdefinition*}
The definition leads to the following consequences:
\begin{itemize}
  \item \(\P(a \leq x \leq b) = \P(a < x < b)\)
  \item \(\P(X = x) = 0\)
  \item \(\P(X \in [a, b]) = \P(X \in (a, b))\)
  \item \(F_x\) differentiable \(\implies \frac{dF_x}{dx}(x_0) = f_x(x_0)\)
\end{itemize}
